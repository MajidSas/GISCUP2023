{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2c37f9eeda0c43e59feb0e6690473822":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d56186f69194018b766db27546d530d","IPY_MODEL_5a5e7efe49004edbac33e42eeaa44093","IPY_MODEL_83536de81e7543538f1d3932af81dc17"],"layout":"IPY_MODEL_c07a8f54be9d4476993e4723220938b0"}},"4d56186f69194018b766db27546d530d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_deeddd7637934ffc90e9b3e6169acbd9","placeholder":"​","style":"IPY_MODEL_96e2a03cd2314ea888d12331bde47a98","value":"Predicting DataLoader 0: 100%"}},"5a5e7efe49004edbac33e42eeaa44093":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9effa322a086448b83251fea61402e90","max":5763,"min":0,"orientation":"horizontal","style":"IPY_MODEL_701fded32bba49c781a1cef13022a358","value":5763}},"83536de81e7543538f1d3932af81dc17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6532f848d6324a6d90db45d8dd921e81","placeholder":"​","style":"IPY_MODEL_879f1c10c5274a0b8d3dd523b4d9e9dd","value":" 5763/5763 [11:40&lt;00:00,  8.23it/s]"}},"c07a8f54be9d4476993e4723220938b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"deeddd7637934ffc90e9b3e6169acbd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96e2a03cd2314ea888d12331bde47a98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9effa322a086448b83251fea61402e90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"701fded32bba49c781a1cef13022a358":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6532f848d6324a6d90db45d8dd921e81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"879f1c10c5274a0b8d3dd523b4d9e9dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U5_hHiv7Twei","executionInfo":{"status":"ok","timestamp":1696193328062,"user_tz":420,"elapsed":36950,"user":{"displayName":"Majid Saeedan","userId":"15858486868345744537"}},"outputId":"d57b41d5-0b07-4546-e280-34036529adb8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/PyTorchLightning/pytorch-lightning\n","  Cloning https://github.com/PyTorchLightning/pytorch-lightning to /tmp/pip-req-build-rehbwyvm\n","  Running command git clone --filter=blob:none --quiet https://github.com/PyTorchLightning/pytorch-lightning /tmp/pip-req-build-rehbwyvm\n","  Resolved https://github.com/PyTorchLightning/pytorch-lightning to commit d1f8b0f7669aa808df5fcc2934455be3c83b4bae\n","  Running command git submodule update --init --recursive -q\n","  Encountered 31 file(s) that should have been pointers, but weren't:\n","        .notebooks/course_UvA-DL/01-introduction-to-pytorch.ipynb\n","        .notebooks/course_UvA-DL/02-activation-functions.ipynb\n","        .notebooks/course_UvA-DL/03-initialization-and-optimization.ipynb\n","        .notebooks/course_UvA-DL/04-inception-resnet-densenet.ipynb\n","        .notebooks/course_UvA-DL/05-transformers-and-MH-attention.ipynb\n","        .notebooks/course_UvA-DL/06-graph-neural-networks.ipynb\n","        .notebooks/course_UvA-DL/07-deep-energy-based-generative-models.ipynb\n","        .notebooks/course_UvA-DL/08-deep-autoencoders.ipynb\n","        .notebooks/course_UvA-DL/09-normalizing-flows.ipynb\n","        .notebooks/course_UvA-DL/10-autoregressive-image-modeling.ipynb\n","        .notebooks/course_UvA-DL/11-vision-transformer.ipynb\n","        .notebooks/course_UvA-DL/12-meta-learning.ipynb\n","        .notebooks/course_UvA-DL/13-contrastive-learning.ipynb\n","        .notebooks/flash_tutorials/electricity_forecasting.ipynb\n","        .notebooks/flash_tutorials/image_classification.ipynb\n","        .notebooks/flash_tutorials/tabular_classification.ipynb\n","        .notebooks/flash_tutorials/text_classification.ipynb\n","        .notebooks/lightning_examples/augmentation_kornia.ipynb\n","        .notebooks/lightning_examples/barlow-twins.ipynb\n","        .notebooks/lightning_examples/basic-gan.ipynb\n","        .notebooks/lightning_examples/cifar10-baseline.ipynb\n","        .notebooks/lightning_examples/datamodules.ipynb\n","        .notebooks/lightning_examples/finetuning-scheduler.ipynb\n","        .notebooks/lightning_examples/mnist-hello-world.ipynb\n","        .notebooks/lightning_examples/mnist-tpu-training.ipynb\n","        .notebooks/lightning_examples/reinforce-learning-DQN.ipynb\n","        .notebooks/lightning_examples/text-transformers.ipynb\n","        .notebooks/lightning_examples/warp-drive.ipynb\n","        .notebooks/templates/img-classify.ipynb\n","        .notebooks/templates/simple.ipynb\n","        .notebooks/templates/titanic.ipynb\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy==1.26.0 in /usr/local/lib/python3.10/dist-packages (1.26.0)\n","Requirement already satisfied: rasterio==1.3.8 in /usr/local/lib/python3.10/dist-packages (1.3.8)\n","Requirement already satisfied: shapely==2.0.1 in /usr/local/lib/python3.10/dist-packages (2.0.1)\n","Requirement already satisfied: geopandas==0.14.0 in /usr/local/lib/python3.10/dist-packages (0.14.0)\n","Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: torchvision==0.15.2 in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n","Requirement already satisfied: affine in /usr/local/lib/python3.10/dist-packages (from rasterio==1.3.8) (2.4.0)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio==1.3.8) (23.1.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio==1.3.8) (2023.7.22)\n","Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio==1.3.8) (8.1.7)\n","Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio==1.3.8) (0.7.2)\n","Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from rasterio==1.3.8) (1.4.7)\n","Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio==1.3.8) (1.1.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio==1.3.8) (67.7.2)\n","Requirement already satisfied: fiona>=1.8.21 in /usr/local/lib/python3.10/dist-packages (from geopandas==0.14.0) (1.9.4.post1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas==0.14.0) (23.1)\n","Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from geopandas==0.14.0) (1.5.3)\n","Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from geopandas==0.14.0) (3.6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (2.0.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (9.4.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (16.0.6)\n","Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning==2.1.0rc0) (6.0.1)\n","Requirement already satisfied: fsspec[http]<2025.0,>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.1.0rc0) (2023.6.0)\n","Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.1.0rc0) (0.9.0)\n","Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.1.0rc0) (1.2.0)\n","Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.1.0rc0) (4.66.1)\n","Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning==2.1.0rc0) (2.0.9.post0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->geopandas==0.14.0) (1.16.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>2021.06.0->lightning==2.1.0rc0) (3.8.5)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas==0.14.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas==0.14.0) (2023.3.post1)\n","Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio==1.3.8) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (2.0.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning==2.1.0rc0) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning==2.1.0rc0) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning==2.1.0rc0) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning==2.1.0rc0) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning==2.1.0rc0) (1.3.1)\n"]}],"source":["! pip install numpy==1.26.0 rasterio==1.3.8 shapely==2.0.1 geopandas==0.14.0 torch==2.0.1 torchvision==0.15.2 git+https://github.com/PyTorchLightning/pytorch-lightning"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BTSM1Oy7UM0e","executionInfo":{"status":"ok","timestamp":1696193329656,"user_tz":420,"elapsed":1601,"user":{"displayName":"Majid Saeedan","userId":"15858486868345744537"}},"outputId":"8b079e6b-e085-460d-888c-8b8723562f29"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# the folder in Google Drive that contains:\n","## 'test' folder with test rasters\n","## 'filter_dem' containing the ArcticDEM preprocessed rasters\n","## the saved model checkpoint with the best dice_coeff\n","## 'predictions' a folder where the prediced rasters will be saved\n","BASE_FOLDER = '/content/drive/MyDrive/Research/SIGSPATIAL Competition/data'\n","\n","# the same folder is available here:\n","# https://drive.google.com/drive/folders/1cGyDLLmZafQGetRfnqp8NPGrozed6nx-?usp=sharing\n","# you can copy it and update the path to where it is copied in your directory"],"metadata":{"id":"fvB5T08RbVzE","executionInfo":{"status":"ok","timestamp":1696193329656,"user_tz":420,"elapsed":4,"user":{"displayName":"Majid Saeedan","userId":"15858486868345744537"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["! rm -rf ./test_tiles"],"metadata":{"id":"dOwCP839ZayJ","executionInfo":{"status":"ok","timestamp":1696193334262,"user_tz":420,"elapsed":4610,"user":{"displayName":"Majid Saeedan","userId":"15858486868345744537"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["import os\n","import rasterio\n","import numpy as np\n","import pandas as pd\n","import torch\n","import sys\n","from glob import glob\n","#import torchvision\n","\n","output_dir = '.'\n","print(\"output directory: \"+ output_dir)\n","os.makedirs(output_dir+'/test_tiles')\n","\n","\n","DIM = 256\n","Step = 1\n","\n","csv_f = open(output_dir + '/test_tile_info.csv', 'w')\n","csv_f.write('region_id\\traster_id\\tx\\ty\\n')\n","# index = 0\n","for region_id in range(1,7):\n","    print(region_id)\n","    raster_paths = glob(BASE_FOLDER + '/test/region_0%d/*.tif' % region_id)\n","    dem_paths = BASE_FOLDER + '/filter_dem/dem_region_0%d.tif' % region_id\n","\n","    dem = rasterio.open(dem_paths)\n","    dem_read = dem.read()\n","    dem_avg = np.mean(dem.read()[dem != -9999.0])\n","\n","\n","    for raster_path in raster_paths:\n","        raster_id = raster_path[raster_path.find('_2019')+1:raster_path.find('.tif')]\n","        raster = rasterio.open(raster_path)\n","\n","        raster_arr = raster.read()\n","        min_shape_1 = min(raster_arr.shape[1],dem_read.shape[1])\n","        min_shape_2 = min(raster_arr.shape[2],dem_read.shape[2])\n","        x_pad = DIM-(min_shape_1%DIM)\n","        y_pad = DIM-(min_shape_2%DIM)\n","\n","        dem_arr = np.pad(dem_read, ((0,0), (0, x_pad), (0, y_pad)), 'reflect')\n","        dem_arr[dem_arr == -9999.0] = dem_avg\n","        for x in range(0, min_shape_1-DIM+Step, DIM // Step):\n","            for y in range(0, min_shape_2-DIM+Step, DIM // Step):\n","                cropped_dem = dem_arr[:, x:x+DIM, y:y+DIM]\n","                cropped_raster = raster_arr[:, x:x+DIM, y:y+DIM]\n","                if len(cropped_dem) > 0 and cropped_dem.mean() > 800:\n","                    cropped_dem = ( cropped_dem - 28.320312 ) / (2468.8047 - 28.320312)\n","                    #sum_value = cropped_label.sum()\n","                    a1 = cropped_raster.astype('float32')/255.0\n","                    a2 = cropped_dem.astype('float32')\n","                    a3 = np.zeros((4,DIM,DIM))\n","                    a3[0:3] = a1\n","                    a3[3] = a2\n","                    tensor = torch.from_numpy(a3)\n","                    torch.save(tensor, output_dir + '/test_tiles/%d_%s_%d_%d.pt' % (region_id, raster_id, x, y))\n","\n","                    csv_f.write(str(region_id) +  '\\t' + raster_id + '\\t' + str(x) +'\\t' + str(y)  +'\\n')\n","csv_f.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iMwhlN6_UjrC","executionInfo":{"status":"ok","timestamp":1696193843803,"user_tz":420,"elapsed":509548,"user":{"displayName":"Majid Saeedan","userId":"15858486868345744537"}},"outputId":"d1f39baa-95a6-466d-ca89-f020ed72bbbe"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["output direction: .\n","1\n","2\n","3\n","4\n","5\n","6\n"]}]},{"cell_type":"code","source":["model_checkpoint = BASE_FOLDER + '/unet-epoch=243-dice_coeff=0.82.ckpt'"],"metadata":{"id":"MHfBI97VaClQ","executionInfo":{"status":"ok","timestamp":1696193843806,"user_tz":420,"elapsed":27,"user":{"displayName":"Majid Saeedan","userId":"15858486868345744537"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["from __future__ import print_function, division\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset\n","import lightning.pytorch as pl\n","import torch.utils.data\n","from torch import optim\n","\n","\n","seed = 42\n","\n","\n","def set_seed(seed):\n","    torch.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","\n","\n","set_seed(seed)\n","\n","dataset_dir = \".\"\n","\n","df = pd.read_csv(dataset_dir + '/test_tile_info.csv', sep='\\t')\n","\n","\n","class TileDataset(Dataset):\n","    def __init__(\n","            self,\n","            folder,\n","            is_train=True\n","    ):\n","        super().__init__()\n","        self.folder = folder\n","        self.tile_info = pd.read_csv(folder + '/test_tile_info.csv', sep='\\t')\n","\n","    def __len__(self):\n","        return self.tile_info.shape[0]\n","\n","    def __getitem__(self, index):\n","        region_id, raster_id, x, y = self.tile_info.iloc[index].values\n","        filename = '%d_%s_%d_%d.pt' % (region_id, raster_id, x, y)\n","        tile = torch.load(self.folder + '/test_tiles/' + filename)\n","        return tile.to(torch.float32)\n","\n","\n","torch.set_default_dtype(torch.float32)\n","\n","\n","class conv_block(nn.Module):\n","    \"\"\"\n","    Convolution Block\n","    \"\"\"\n","\n","    def __init__(self, in_ch, out_ch, dropout=0):\n","        super(conv_block, self).__init__()\n","\n","        self.conv = nn.Sequential(\n","            nn.Dropout(dropout),\n","            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n","            nn.BatchNorm2d(out_ch),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n","            nn.BatchNorm2d(out_ch),\n","            nn.ReLU(inplace=True))\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        return x\n","\n","\n","class up_conv(nn.Module):\n","    \"\"\"\n","    Up Convolution Block\n","    \"\"\"\n","\n","    def __init__(self, in_ch, out_ch, dropout=0):\n","        super(up_conv, self).__init__()\n","        self.up = nn.Sequential(\n","            nn.Upsample(scale_factor=2),\n","            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n","            nn.BatchNorm2d(out_ch),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        x = self.up(x)\n","        return x\n","\n","\n","class U_Net(nn.Module):\n","    \"\"\"\n","    UNet - Basic Implementation\n","    Paper : https://arxiv.org/abs/1505.04597\n","    \"\"\"\n","\n","    def __init__(self, in_ch=3, out_ch=1):\n","        super(U_Net, self).__init__()\n","\n","        n1 = 64\n","        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n","\n","        self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        # self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        # self.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.Conv1 = conv_block(in_ch, filters[0], 0)\n","        self.Conv2 = conv_block(filters[0], filters[1], 0.1)\n","        self.Conv3 = conv_block(filters[1], filters[2], 0.1)\n","        # self.Conv4 = conv_block(filters[2], filters[3], 0.1)\n","        # self.Conv5 = conv_block(filters[3], filters[4], 0.1)\n","\n","        # self.Up5 = up_conv(filters[4], filters[3])\n","        # self.Up_conv5 = conv_block(filters[4], filters[3], 0.1)\n","\n","        # self.Up4 = up_conv(filters[3], filters[2])\n","        # self.Up_conv4 = conv_block(filters[3], filters[2], 0.1)\n","\n","        self.Up3 = up_conv(filters[2], filters[1])\n","        self.Up_conv3 = conv_block(filters[2], filters[1], 0.1)\n","\n","        self.Up2 = up_conv(filters[1], filters[0])\n","        self.Up_conv2 = conv_block(filters[1], filters[0], 0.1)\n","\n","        self.Conv = nn.Conv2d(filters[0], out_ch, kernel_size=1, stride=1, padding=0)\n","\n","        self.active = torch.nn.Sigmoid()\n","\n","    def forward(self, x):\n","        e1 = self.Conv1(x)\n","\n","        e2 = self.Maxpool1(e1)\n","        e2 = self.Conv2(e2)\n","\n","        e3 = self.Maxpool2(e2)\n","        e3 = self.Conv3(e3)\n","\n","        # e4 = self.Maxpool3(e3)\n","        # e4 = self.Conv4(e4)\n","\n","        # e5 = self.Maxpool4(e4)\n","        # e5 = self.Conv5(e5)\n","\n","        # d5 = self.Up5(e5)\n","        # d5 = torch.cat((e4, d5), dim=1)\n","\n","        # d5 = self.Up_conv5(d5)\n","\n","        # d4 = self.Up4(d5)\n","        # d4 = torch.cat((e3, d4), dim=1)\n","        # d4 = self.Up_conv4(d4)\n","\n","        d3 = self.Up3(e3)  # d4\n","        d3 = torch.cat((e2, d3), dim=1)\n","        d3 = self.Up_conv3(d3)\n","\n","        d2 = self.Up2(d3)\n","        d2 = torch.cat((e1, d2), dim=1)\n","        d2 = self.Up_conv2(d2)\n","\n","        d1 = self.Conv(d2)\n","\n","        out = self.active(d1)\n","\n","        return out\n","\n","\n","class LitU_net(pl.LightningModule):\n","    def __init__(self):\n","        super().__init__()\n","        self.unet = U_Net(4, 1)\n","\n","    def forward(self, x):\n","        return self.unet(x)\n","\n","    def training_step(self, batch):\n","        x, y = batch\n","        y_pred = self.forward(x)\n","        loss = self.dice_loss(y_pred, y)\n","        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","        return loss\n","\n","    def validation_step(self, batch):\n","        x, y = batch\n","        y_pred = self.forward(x)\n","        loss = self.dice_loss(y_pred, y)\n","        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","        self.log(\"dice_coeff\", self.dice_coeff(y_pred, y), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","        return y_pred\n","\n","    def predict_step(self, batch):\n","        # x, y = batch\n","        y_pred = self.forward(batch)\n","        return y_pred\n","\n","    def configure_optimizers(self):\n","        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n","        return optimizer\n","\n","    def dice_loss(self, logits, targets):\n","        intersection = 2 * (logits * targets).sum() + 1  # self.smooth\n","        union = (logits + targets).sum() + 1  # self.smooth\n","        dice_loss = 1. - intersection / union\n","\n","        loss = nn.BCELoss()\n","        bce_loss = loss(logits, targets)\n","        return 0.5 * dice_loss + 0.5 * bce_loss\n","\n","    def dice_coeff(self, logits, targets):\n","        intersection = 2 * (logits * targets).sum()\n","        union = (logits + targets).sum()\n","        if union == 0:\n","            return 1\n","        dice_coeff = intersection / union\n","        return dice_coeff.item()\n","\n","\n","batch_size = 8\n","num_workers = 12\n","\n","test_loader = torch.utils.data.DataLoader(TileDataset(dataset_dir), batch_size=batch_size, num_workers=num_workers)\n","\n","model = LitU_net.load_from_checkpoint(model_checkpoint)\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"St9s8-aiYj_5","executionInfo":{"status":"ok","timestamp":1696193845712,"user_tz":420,"elapsed":1926,"user":{"displayName":"Majid Saeedan","userId":"15858486868345744537"}},"outputId":"eb1122ce-4c1a-468e-ea3c-337336bbbf58"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"execute_result","data":{"text/plain":["LitU_net(\n","  (unet): U_Net(\n","    (Maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (Maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (Conv1): conv_block(\n","      (conv): Sequential(\n","        (0): Dropout(p=0, inplace=False)\n","        (1): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (3): ReLU(inplace=True)\n","        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (6): ReLU(inplace=True)\n","      )\n","    )\n","    (Conv2): conv_block(\n","      (conv): Sequential(\n","        (0): Dropout(p=0.1, inplace=False)\n","        (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (3): ReLU(inplace=True)\n","        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (6): ReLU(inplace=True)\n","      )\n","    )\n","    (Conv3): conv_block(\n","      (conv): Sequential(\n","        (0): Dropout(p=0.1, inplace=False)\n","        (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (3): ReLU(inplace=True)\n","        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (6): ReLU(inplace=True)\n","      )\n","    )\n","    (Up3): up_conv(\n","      (up): Sequential(\n","        (0): Upsample(scale_factor=2.0, mode='nearest')\n","        (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (3): ReLU(inplace=True)\n","      )\n","    )\n","    (Up_conv3): conv_block(\n","      (conv): Sequential(\n","        (0): Dropout(p=0.1, inplace=False)\n","        (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (3): ReLU(inplace=True)\n","        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (6): ReLU(inplace=True)\n","      )\n","    )\n","    (Up2): up_conv(\n","      (up): Sequential(\n","        (0): Upsample(scale_factor=2.0, mode='nearest')\n","        (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (3): ReLU(inplace=True)\n","      )\n","    )\n","    (Up_conv2): conv_block(\n","      (conv): Sequential(\n","        (0): Dropout(p=0.1, inplace=False)\n","        (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (3): ReLU(inplace=True)\n","        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (6): ReLU(inplace=True)\n","      )\n","    )\n","    (Conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n","    (active): Sigmoid()\n","  )\n",")"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["trainer = pl.Trainer(accelerator=\"gpu\")\n","predictions = trainer.predict(model, test_loader)"],"metadata":{"id":"GT3vtJpvWfUn","colab":{"base_uri":"https://localhost:8080/","height":326,"referenced_widgets":["2c37f9eeda0c43e59feb0e6690473822","4d56186f69194018b766db27546d530d","5a5e7efe49004edbac33e42eeaa44093","83536de81e7543538f1d3932af81dc17","c07a8f54be9d4476993e4723220938b0","deeddd7637934ffc90e9b3e6169acbd9","96e2a03cd2314ea888d12331bde47a98","9effa322a086448b83251fea61402e90","701fded32bba49c781a1cef13022a358","6532f848d6324a6d90db45d8dd921e81","879f1c10c5274a0b8d3dd523b4d9e9dd"]},"outputId":"4c321324-9506-45c8-d3b3-e5c1191e6cc7","executionInfo":{"status":"ok","timestamp":1696194555090,"user_tz":420,"elapsed":207352,"user":{"displayName":"Majid Saeedan","userId":"15858486868345744537"}}},"execution_count":20,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: IPU available: False, using: 0 IPUs\n","INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO: HPU available: False, using: 0 HPUs\n","INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","WARNING: Missing logger folder: /content/lightning_logs\n","WARNING:lightning.pytorch.loggers.tensorboard:Missing logger folder: /content/lightning_logs\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c37f9eeda0c43e59feb0e6690473822","version_major":2,"version_minor":0},"text/plain":["Predicting: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}]},{"cell_type":"code","source":["import rasterio\n","import fiona\n","import rasterio.features\n","from rasterio.crs import CRS\n","from rasterio.features import rasterize\n","import shapely\n","from shapely import wkt\n","from shapely import envelope\n","from shapely.geometry import shape, mapping\n","from shapely.geometry.polygon import Polygon, LineString\n","import geopandas as gpd\n","from shapely.geometry.multipoint import MultiPoint\n","from shapely import buffer"],"metadata":{"id":"owV1mOLimQMI","executionInfo":{"status":"ok","timestamp":1696194556631,"user_tz":420,"elapsed":1542,"user":{"displayName":"Majid Saeedan","userId":"15858486868345744537"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["output_dir = BASE_FOLDER+ '/predictions/'\n","\n","shp_schema = {\n","    'geometry': 'Polygon',\n","    'properties': {\n","    'image': 'str',\n","    'region_num': 'int'}\n","}"],"metadata":{"id":"xB6F7mOZmV9W","executionInfo":{"status":"ok","timestamp":1696194556646,"user_tz":420,"elapsed":3,"user":{"displayName":"Majid Saeedan","userId":"15858486868345744537"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def get_area(polygon, crs):\n","    return gpd.GeoDataFrame({'geometry': [polygon]}, crs=crs).area[0]\n","def process_polygon(polygon, crs):\n","    max_diagonal = -1\n","    area = get_area(polygon, crs)\n","    area2 = area\n","    if area >= 100000:\n","        bounding_rect = MultiPoint(polygon.exterior.coords).minimum_rotated_rectangle\n","        coords = bounding_rect.exterior.coords\n","        for i in range(len(coords)-1):\n","            for j in range(i+1, len(coords)-1):\n","                line = LineString([coords[i], coords[j]])\n","                max_diagonal = max(max_diagonal, line.length)\n","        # this was implemented based on this discussion: https://gis.stackexchange.com/questions/316128/identifying-long-and-narrow-polygons-in-with-postgis\n","        area2 = get_area(buffer(polygon, -0.085*max_diagonal), crs)\n","    return area, area2\n"],"metadata":{"id":"sKaHmwJCo9lh","executionInfo":{"status":"ok","timestamp":1696194556647,"user_tz":420,"elapsed":4,"user":{"displayName":"Majid Saeedan","userId":"15858486868345744537"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["\n","import rasterio\n","tile_info = pd.read_csv('./test_tile_info.csv', sep='\\t')\n","DIM=256\n","crs = 'EPSG:3857'\n","all_shapes = {i: {} for i in range(1,7)}\n","\n","for region_id in range(1,7):\n","  raster_ids = np.unique(tile_info[tile_info['region_id'] == region_id]['raster_id'].values)\n","  print(raster_ids)\n","  for raster_id in raster_ids:\n","    raster = rasterio.open('/content/drive/MyDrive/Research/SIGSPATIAL Competition/data/test/region_0%d/Greenland26X_22W_Sentinel2_%s.tif' % (region_id, raster_id))\n","    raster_arr =raster.read()\n","    x_pad = DIM-(raster_arr.shape[1]%DIM)\n","    y_pad = DIM-(raster_arr.shape[2]%DIM)\n","    merged_labels = np.zeros((1, raster_arr.shape[1]+x_pad, raster_arr.shape[2]+y_pad),dtype=np.int32)\n","    tile_index = 0\n","    mask = (tile_info['region_id'] == region_id) & (tile_info['raster_id'] == raster_id)\n","    print(region_id, raster_id, mask.sum())\n","    for i in range(len(predictions)):\n","      for j in range(predictions[i].shape[0]):\n","        if mask[tile_index]:\n","          tile_pred = predictions[i][j].numpy()\n","          region_id, raster_id, x, y = tile_info.iloc[tile_index]\n","          tile_pred[tile_pred < 0.1] = 0\n","          tile_pred[tile_pred >= 0.1] = 1\n","\n","          merged_labels[0, x:x+DIM, y:y+DIM] = tile_pred\n","        tile_index+=1\n","\n","    with rasterio.open(\n","        BASE_FOLDER + '/predictions/%d_%s.tif' % (region_id, raster_id), \"w\",\n","        driver = \"GTiff\",\n","        crs = raster.crs,\n","        transform = raster.transform,\n","        dtype = rasterio.uint8,\n","        count = 1,\n","        width = raster.width,\n","        height = raster.height) as dst:\n","        dst.write(merged_labels[0,0:raster_arr.shape[1], 0:raster_arr.shape[2]], indexes = 1)\n","    mask = merged_labels == 1\n","\n","    detected_shapes = rasterio.features.shapes(merged_labels, connectivity=8, transform=raster.transform)\n","    shapes = []\n","    for geom, value in detected_shapes:\n","        if value > 0:\n","            polygon = Polygon(shape(geom)).convex_hull\n","            area, area2 = process_polygon(polygon, crs)\n","            if area < 10000:\n","                continue\n","            if area2 ==  0:\n","                print(\"skipping narrow shape\")\n","                continue\n","            shapes.append(polygon)\n","\n","    gdf = gpd.GeoDataFrame({'geometry': shapes}, crs=crs)\n","    gdf['geometry'] = gdf['geometry'].buffer(120)\n","    gdf = gdf.dissolve().explode(index_parts=True)\n","    all_shapes[region_id][raster_id] = gdf"],"metadata":{"id":"URcpmUFRbPVD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696195042631,"user_tz":420,"elapsed":390327,"user":{"displayName":"Majid Saeedan","userId":"15858486868345744537"}},"outputId":"71195d17-b1f8-4d1e-ca3e-3691852fd033"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["['2019-06-03_05' '2019-07-31_25']\n","1 2019-06-03_05 1560\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","1 2019-07-31_25 1560\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","['2019-06-19_20' '2019-08-25_29']\n","2 2019-06-19_20 1494\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","2 2019-08-25_29 1494\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","['2019-06-03_05' '2019-07-31_25']\n","3 2019-06-03_05 1700\n","3 2019-07-31_25 1700\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","['2019-06-19_20' '2019-08-25_29']\n","4 2019-06-19_20 1772\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","4 2019-08-25_29 1772\n","skipping narrow shape\n","['2019-06-03_05' '2019-07-31_25']\n","5 2019-06-03_05 8310\n","skipping narrow shape\n","5 2019-07-31_25 8310\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","['2019-06-19_20' '2019-08-25_29']\n","6 2019-06-19_20 8216\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","6 2019-08-25_29 8216\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n","skipping narrow shape\n"]}]},{"cell_type":"code","source":["with fiona.open(BASE_FOLDER+'/lake_polygons_test.gpkg', 'w', 'GPKG',shp_schema, crs) as shp:\n","  for region_id in all_shapes:\n","    for raster_id in all_shapes[region_id]:\n","      shapes = all_shapes[region_id][raster_id]['geometry'].values\n","      image = 'Greenland26X_22W_Sentinel2_%s.tif' % raster_id\n","      print(region_id, image)\n","      for polygon in shapes:\n","        polygon = polygon.convex_hull\n","        shp.write({\n","            'geometry': mapping(polygon),\n","            'properties': {\n","            'image':image,\n","            'region_num': int(region_id)\n","            }\n","        })\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KPYlnkWho5PY","executionInfo":{"status":"ok","timestamp":1696195227327,"user_tz":420,"elapsed":184048,"user":{"displayName":"Majid Saeedan","userId":"15858486868345744537"}},"outputId":"44f28455-468f-49a6-fb6c-b166edc2b74c"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["1 Greenland26X_22W_Sentinel2_2019-06-03_05.tif\n","1 Greenland26X_22W_Sentinel2_2019-07-31_25.tif\n","2 Greenland26X_22W_Sentinel2_2019-06-19_20.tif\n","2 Greenland26X_22W_Sentinel2_2019-08-25_29.tif\n","3 Greenland26X_22W_Sentinel2_2019-06-03_05.tif\n","3 Greenland26X_22W_Sentinel2_2019-07-31_25.tif\n","4 Greenland26X_22W_Sentinel2_2019-06-19_20.tif\n","4 Greenland26X_22W_Sentinel2_2019-08-25_29.tif\n","5 Greenland26X_22W_Sentinel2_2019-06-03_05.tif\n","5 Greenland26X_22W_Sentinel2_2019-07-31_25.tif\n","6 Greenland26X_22W_Sentinel2_2019-06-19_20.tif\n","6 Greenland26X_22W_Sentinel2_2019-08-25_29.tif\n"]}]}]}